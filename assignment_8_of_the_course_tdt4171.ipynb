{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29ec37ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from typing import Dict, List, Any, Union\n",
    "import numpy as np\n",
    "# Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.python.framework.random_seed import set_random_seed\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2364fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data() -> Dict[str, Union[List[Any], int]]:\n",
    "    path = \"keras-data.pickle\"\n",
    "    with open(file=path, mode=\"rb\") as file:\n",
    "        data = pickle.load(file)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c1ed979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data: Dict[str, Union[List[Any], int]]) -> Dict[str, Union[List[Any], np.ndarray, int]]:\n",
    "    \"\"\"\n",
    "    Preprocesses the data dictionary. Both the training-data and the test-data must be padded\n",
    "    to the same length; play around with the maxlen parameter to trade off speed and accuracy.\n",
    "    \"\"\"\n",
    "    maxlen = data[\"max_length\"]//16\n",
    "    data[\"x_train\"] = pad_sequences(data['x_train'], maxlen=maxlen)\n",
    "    data[\"y_train\"] = np.asarray(data['y_train'])\n",
    "    data[\"x_test\"] = pad_sequences(data['x_test'], maxlen=maxlen)\n",
    "    data[\"y_test\"] = np.asarray(data['y_test'])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4fd9086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data: Dict[str, Union[List[Any], np.ndarray, int]], model_type=\"feedforward\") -> float:\n",
    "    \"\"\"\n",
    "    Build a neural network of type model_type and train the model on the data.\n",
    "    Evaluate the accuracy of the model on test data.\n",
    "\n",
    "    :param data: The dataset dictionary to train neural network on\n",
    "    :param model_type: The model to be trained, either \"feedforward\" for feedforward network\n",
    "                        or \"recurrent\" for recurrent network\n",
    "    :return: The accuracy of the model on test data\n",
    "    \"\"\"\n",
    "    # Configuration options\n",
    "    #see the number of labels\n",
    "    labels = set(data[\"y_train\"])\n",
    "    print(labels, len(labels))\n",
    "\n",
    "    # Configuration options\n",
    "    feature_vector_length = data[\"x_train\"].shape[1] #how many features\n",
    "    num_classes = len(labels) #how many classes\n",
    "    y_train_cat = to_categorical(data[\"y_train\"], num_classes)\n",
    "    y_test_cat = to_categorical(data[\"y_test\"], num_classes)\n",
    "    vocab_size = data[\"vocab_size\"]\n",
    "    maxlen = data[\"max_length\"]//16\n",
    "    if(model_type == \"feedforward\"):\n",
    "        np.random.seed(123)\n",
    "        set_random_seed(2)\n",
    "\n",
    "        #model = Sequential() #we first define how the \"model\" looks like\n",
    "        #model.add(Dense(input_dim = feature_vector_length, units=feature_vector_length , activation='relu')) #input layer\n",
    "        #model.add(Dense(num_classes, activation='softmax')) #output layer\n",
    "        #print(model.summary())\n",
    "        #plot_model(model, show_shapes= True)\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Embedding(input_dim=vocab_size, output_dim=32, input_length=feature_vector_length))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(input_dim = feature_vector_length, units=feature_vector_length , activation='relu')) #input layer\n",
    "        model.add(Dense(num_classes, activation='softmax')) #output layer\n",
    "        \n",
    "        \n",
    "        #model = tf.keras.Sequential([\n",
    "        #tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=32, input_length=input_shape),\n",
    "        #tf.keras.layers.Flatten(),\n",
    "        #tf.keras.layers.Dense(128, activation='relu'),\n",
    "        #tf.keras.layers.Dense(10, activation='softmax')])\n",
    "        \n",
    "        model.compile(loss='categorical_crossentropy', #loss metric\n",
    "        optimizer='sgd',  #optimizer\n",
    "        metrics=['accuracy']) #displayed metric\n",
    "\n",
    "\n",
    "        #fit\n",
    "        history = model.fit(data[\"x_train\"], y_train_cat, epochs=15, batch_size=32, verbose=1, validation_split=0.1)\n",
    "        \n",
    "        # summarize history for accuracy\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'val'], loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "        # summarize history for accuracy\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'val'], loc='upper left')\n",
    "        plt.show()\n",
    "        \n",
    "        #test\n",
    "        \n",
    "        test_results = model.evaluate(data[\"x_test\"], y_test_cat, verbose=1)\n",
    "        print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
    "        return test_results[1]\n",
    "        \n",
    "    elif(model_type == \"recurrent\"):\n",
    "        np.random.seed(123)\n",
    "        set_random_seed(2)\n",
    "        \n",
    "        model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=32, input_length=maxlen),\n",
    "        tf.keras.layers.LSTM(66, dropout=0.2, recurrent_dropout=0.2),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        model.compile(loss='categorical_crossentropy', #loss metric\n",
    "        optimizer='sgd',  #optimizer\n",
    "        metrics=['accuracy']) #displayed metric\n",
    "\n",
    "\n",
    "        #fit\n",
    "        history = model.fit(data[\"x_train\"], y_train_cat, epochs=5, batch_size=32, validation_split=0.2)\n",
    "        \n",
    "        # summarize history for accuracy\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'val'], loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "        # summarize history for accuracy\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'val'], loc='upper left')\n",
    "        plt.show()\n",
    "        \n",
    "        #test\n",
    "        test_results = model.evaluate(data[\"x_test\"], y_test_cat, verbose=1)\n",
    "        print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
    "        return test_results[1]\n",
    "\n",
    "    # TODO build the model given model_type, train it on (data[\"x_train\"], data[\"y_train\"])\n",
    "    #  and evaluate its accuracy on (data[\"x_test\"], data[\"y_test\"]). Return the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44465784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading data...\n",
      "2. Preprocessing data...\n",
      "3. Training feedforward neural network...\n",
      "{0, 1} 2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown optimizer: 'AD'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 18\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel: Recurrent NN.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     13\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrnn_test_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 7\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m keras_data \u001b[38;5;241m=\u001b[39m preprocess_data(keras_data)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3. Training feedforward neural network...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m fnn_test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeras_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeedforward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#print('Model: Feedforward NN.\\n'\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#      f'Test accuracy: {fnn_test_accuracy:.3f}')\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4. Training recurrent neural network...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[22], line 46\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(data, model_type)\u001b[0m\n\u001b[1;32m     37\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(num_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;66;03m#output layer\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#model = tf.keras.Sequential([\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=32, input_length=input_shape),\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#tf.keras.layers.Flatten(),\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#tf.keras.layers.Dense(128, activation='relu'),\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m#tf.keras.layers.Dense(10, activation='softmax')])\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategorical_crossentropy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#loss metric\u001b[39;49;00m\n\u001b[1;32m     47\u001b[0m \u001b[43m\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m#optimizer\u001b[39;49;00m\n\u001b[1;32m     48\u001b[0m \u001b[43m\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#displayed metric\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m#fit\u001b[39;00m\n\u001b[1;32m     52\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_train\u001b[39m\u001b[38;5;124m\"\u001b[39m], y_train_cat, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/mlp/lib/python3.9/site-packages/keras/saving/legacy/serialization.py:385\u001b[0m, in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[0;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m object_registration\u001b[38;5;241m.\u001b[39mget_registered_object(\n\u001b[1;32m    382\u001b[0m     class_name, custom_objects, module_objects\n\u001b[1;32m    383\u001b[0m )\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 385\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprintable_module_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure you are using a `keras.utils.custom_object_scope` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand that this object is included in the scope. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.tensorflow.org/guide/keras/save_and_serialize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    390\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#registering_the_custom_object for details.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m     )\n\u001b[1;32m    393\u001b[0m cls_config \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# Check if `cls_config` is a list. If it is a list, return the class and the\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;66;03m# associated class configs for recursively deserialization. This case will\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;66;03m# happen on the old version of sequential model (e.g. `keras_version` ==\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# \"2.0.6\"), which is serialized in a different structure, for example\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;66;03m# \"{'class_name': 'Sequential',\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m#   'config': [{'class_name': 'Embedding', 'config': ...}, {}, ...]}\".\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown optimizer: 'AD'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
     ]
    }
   ],
   "source": [
    "def main() -> None:\n",
    "    print(\"1. Loading data...\")\n",
    "    keras_data = load_data()\n",
    "    print(\"2. Preprocessing data...\")\n",
    "    keras_data = preprocess_data(keras_data)\n",
    "    print(\"3. Training feedforward neural network...\")\n",
    "    fnn_test_accuracy = train_model(keras_data, model_type=\"feedforward\")\n",
    "    #print('Model: Feedforward NN.\\n'\n",
    "    #      f'Test accuracy: {fnn_test_accuracy:.3f}')\n",
    "    print(\"4. Training recurrent neural network...\")\n",
    "    rnn_test_accuracy = train_model(keras_data, model_type=\"recurrent\")\n",
    "    print('Model: Recurrent NN.\\n'\n",
    "          f'Test accuracy: {rnn_test_accuracy:.3f}')\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
